{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing microstimulation data  <br>\n",
    "# Refer to the proper code for matlab reading it isnt mine\n",
    "\n",
    "## Introduction\n",
    "This notebook file can be used as a guideline for analyzing data concerning the MTL-dependent microstimulation detection task as described in Doron et al. (2020). It is meant to show students or newly interested the step-by-step process from raw data to beautiful graphs. Within this, script the Mouse_Data dataclass and functions from the helpers.py will be explained and used for data-analysis. The analysis will be performed on the data files that are contained within the sibling-folder: 'data'. \n",
    "<br><br>\n",
    "### Importing functions\n",
    "We will start by importing the necessary functions. In order to prevent import or modulenotfound errors it is adviced to mimic the file structure from GitHub. This means that this: 'analysis.ipynb' file should be in the same folder as 'Mouse_Data.py' & 'helpers.py'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we will have to import the dataclass we're using to hold our data, as well as, the helper functions that we'll need.\n",
    "# from Mouse_Data import Mouse_Data\n",
    "from helpers import *\n",
    "\n",
    "# We will also import some additional functions from commonly used packages for convenience and plotting.\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# And suppress an unnessecary error?\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: CHANGE STRUCTURE TO MLAB Importing your data\n",
    "Next we'll import the data we will be analyzing. The example data can be found in the GitHub repository witin the 'data' folder. It is advisable to first do a test run with the example data and make sure you understand the process, before proceding with your own data.\n",
    "The code requires the path to the data folder which in the case of the example data should look something like this: <code>C:Users/username/coding_projects/microstimulation/data</code><br><br>\n",
    "The content of the datafolder is structured in the following way:<br>\n",
    "- ID0\n",
    "    - session0\n",
    "    - session1\n",
    "- ID1\n",
    "    - session0<br>\n",
    "    \n",
    "    \n",
    "Within this datafolder there are subfolders *ID0, ID1* that refer individual animals and their sessions *session0, session1*. Within the folder of each session there should be .txt files that contain the extracted SPIKE2 data. After you have provided the path and checked if it contains the correct data we will load in the data using the Mouse_Data dataclass. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The path you provided contains the following files: \n",
      "['SNA-123598', 'SNA-123599', 'SNA-123601', 'SNA-123602', 'SNA-123995', 'SNA-123996']\n",
      "If you correctly configured your pathing structure this should show the animal ID numbers.\n"
     ]
    }
   ],
   "source": [
    "# Select the path to your data files, replace '\\' with '/' if you copied your path. \n",
    "# Also make sure it ends with '/' so that it's recognized as a folder.\n",
    "root = 'E:/mStim_data/PSI/' #TODO this is for now, change to GitHub example path|\n",
    "datafiles = os.listdir(root)\n",
    "print(f'The path you provided contains the following files: \\n{datafiles}')\n",
    "print('If you correctly configured your pathing structure this should show the animal ID numbers.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta.txt\n",
      "SNA-123598_microstim_20230803_114747.mat\n",
      "SNA-123598_microstim_20230803_122241.mat\n",
      "2023-08-03\n",
      "WARNING: There is already data loaded for the session on 2023-08-03.\n",
      "Please check validity.\n",
      "SNA-123598_microstim_20230804_102701.mat\n",
      "SNA-123598_microstim_20230805_101842.mat\n",
      "SNA-123598_microstim_20230806_153250.mat\n",
      "SNA-123598_microstim_20230807_102754.mat\n",
      "SNA-123598_microstim_20230808_104836.mat\n",
      "meta.txt\n",
      "SNA-123599_microstim_20230803_130542.mat\n",
      "SNA-123599_microstim_20230804_130514.mat\n",
      "SNA-123599_microstim_20230805_114941.mat\n",
      "SNA-123599_microstim_20230805_115057.mat\n",
      "2023-08-05\n",
      "WARNING: There is already data loaded for the session on 2023-08-05.\n",
      "Please check validity.\n",
      "SNA-123599_microstim_20230806_165302.mat\n",
      "SNA-123599_microstim_20230807_121013.mat\n",
      "meta.txt\n",
      "SNA-123601_microstim_20230807_151515.mat\n",
      "SNA-123601_microstim_20230808_143850.mat\n",
      "SNA-123601_microstim_20230809_102201.mat\n",
      "SNA-123601_microstim_20230810_102553.mat\n",
      "SNA-123601_microstim_20230811_125327.mat\n"
     ]
    },
    {
     "ename": "MatReadError",
     "evalue": "Mat file appears to be empty",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMatReadError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\miksc\\OneDrive\\coding_projects\\Microstimulation\\code\\analysis2.ipynb Cell 5\u001b[0m line \u001b[0;36m<cell line: 154>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/miksc/OneDrive/coding_projects/Microstimulation/code/analysis2.ipynb#W4sZmlsZQ%3D%3D?line=153'>154</a>\u001b[0m \u001b[39mfor\u001b[39;00m ID \u001b[39min\u001b[39;00m datafiles:\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/miksc/OneDrive/coding_projects/Microstimulation/code/analysis2.ipynb#W4sZmlsZQ%3D%3D?line=154'>155</a>\u001b[0m     path_to_data \u001b[39m=\u001b[39m root\u001b[39m+\u001b[39mID\u001b[39m+\u001b[39mBPOD_path\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/miksc/OneDrive/coding_projects/Microstimulation/code/analysis2.ipynb#W4sZmlsZQ%3D%3D?line=155'>156</a>\u001b[0m     mouse \u001b[39m=\u001b[39m Mouse_Data(path_to_data)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/miksc/OneDrive/coding_projects/Microstimulation/code/analysis2.ipynb#W4sZmlsZQ%3D%3D?line=156'>157</a>\u001b[0m     mouse_list\u001b[39m.\u001b[39mappend(mouse)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/miksc/OneDrive/coding_projects/Microstimulation/code/analysis2.ipynb#W4sZmlsZQ%3D%3D?line=157'>158</a>\u001b[0m \u001b[39mprint\u001b[39m(mouse_list)\n",
      "\u001b[1;32mc:\\Users\\miksc\\OneDrive\\coding_projects\\Microstimulation\\code\\analysis2.ipynb Cell 5\u001b[0m line \u001b[0;36mMouse_Data.__init__\u001b[1;34m(self, path_to_data)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/miksc/OneDrive/coding_projects/Microstimulation/code/analysis2.ipynb#W4sZmlsZQ%3D%3D?line=115'>116</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfiles \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mlistdir(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/miksc/OneDrive/coding_projects/Microstimulation/code/analysis2.ipynb#W4sZmlsZQ%3D%3D?line=116'>117</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfiles[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/miksc/OneDrive/coding_projects/Microstimulation/code/analysis2.ipynb#W4sZmlsZQ%3D%3D?line=117'>118</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_behaviour()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/miksc/OneDrive/coding_projects/Microstimulation/code/analysis2.ipynb#W4sZmlsZQ%3D%3D?line=118'>119</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msessions \u001b[39m=\u001b[39m [\u001b[39mstr\u001b[39m(key) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession_data\u001b[39m.\u001b[39mkeys()]\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/miksc/OneDrive/coding_projects/Microstimulation/code/analysis2.ipynb#W4sZmlsZQ%3D%3D?line=119'>120</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompile_data()\n",
      "\u001b[1;32mc:\\Users\\miksc\\OneDrive\\coding_projects\\Microstimulation\\code\\analysis2.ipynb Cell 5\u001b[0m line \u001b[0;36mMouse_Data.get_behaviour\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/miksc/OneDrive/coding_projects/Microstimulation/code/analysis2.ipynb#W4sZmlsZQ%3D%3D?line=126'>127</a>\u001b[0m \u001b[39mprint\u001b[39m(file)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/miksc/OneDrive/coding_projects/Microstimulation/code/analysis2.ipynb#W4sZmlsZQ%3D%3D?line=127'>128</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mmeta\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m file:\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/miksc/OneDrive/coding_projects/Microstimulation/code/analysis2.ipynb#W4sZmlsZQ%3D%3D?line=128'>129</a>\u001b[0m     rawData \u001b[39m=\u001b[39m load_mat(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpath \u001b[39m+\u001b[39;49m file)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/miksc/OneDrive/coding_projects/Microstimulation/code/analysis2.ipynb#W4sZmlsZQ%3D%3D?line=129'>130</a>\u001b[0m     session \u001b[39m=\u001b[39m rawData[\u001b[39m'\u001b[39m\u001b[39m__header__\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mdecode()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/miksc/OneDrive/coding_projects/Microstimulation/code/analysis2.ipynb#W4sZmlsZQ%3D%3D?line=130'>131</a>\u001b[0m     session \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39mMon |Tue |Wed |Thu |Fri |Sat |Sun \u001b[39m\u001b[39m'\u001b[39m, session)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \n",
      "\u001b[1;32mc:\\Users\\miksc\\OneDrive\\coding_projects\\Microstimulation\\code\\analysis2.ipynb Cell 5\u001b[0m line \u001b[0;36mload_mat\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/miksc/OneDrive/coding_projects/Microstimulation/code/analysis2.ipynb#W4sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/miksc/OneDrive/coding_projects/Microstimulation/code/analysis2.ipynb#W4sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m ndarray\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/miksc/OneDrive/coding_projects/Microstimulation/code/analysis2.ipynb#W4sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m data \u001b[39m=\u001b[39m scipy\u001b[39m.\u001b[39;49mio\u001b[39m.\u001b[39;49mloadmat(filename, struct_as_record\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, squeeze_me\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/miksc/OneDrive/coding_projects/Microstimulation/code/analysis2.ipynb#W4sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _check_vars(data)\n",
      "File \u001b[1;32mc:\\Users\\miksc\\anaconda3\\envs\\microstim\\lib\\site-packages\\scipy\\io\\matlab\\mio.py:225\u001b[0m, in \u001b[0;36mloadmat\u001b[1;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[0;32m    223\u001b[0m variable_names \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mvariable_names\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    224\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_context(file_name, appendmat) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m--> 225\u001b[0m     MR, _ \u001b[39m=\u001b[39m mat_reader_factory(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    226\u001b[0m     matfile_dict \u001b[39m=\u001b[39m MR\u001b[39m.\u001b[39mget_variables(variable_names)\n\u001b[0;32m    228\u001b[0m \u001b[39mif\u001b[39;00m mdict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\miksc\\anaconda3\\envs\\microstim\\lib\\site-packages\\scipy\\io\\matlab\\mio.py:74\u001b[0m, in \u001b[0;36mmat_reader_factory\u001b[1;34m(file_name, appendmat, **kwargs)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[39mCreate reader for matlab .mat format files.\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     71\u001b[0m \n\u001b[0;32m     72\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     73\u001b[0m byte_stream, file_opened \u001b[39m=\u001b[39m _open_file(file_name, appendmat)\n\u001b[1;32m---> 74\u001b[0m mjv, mnv \u001b[39m=\u001b[39m get_matfile_version(byte_stream)\n\u001b[0;32m     75\u001b[0m \u001b[39mif\u001b[39;00m mjv \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     76\u001b[0m     \u001b[39mreturn\u001b[39;00m MatFile4Reader(byte_stream, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs), file_opened\n",
      "File \u001b[1;32mc:\\Users\\miksc\\anaconda3\\envs\\microstim\\lib\\site-packages\\scipy\\io\\matlab\\miobase.py:214\u001b[0m, in \u001b[0;36mget_matfile_version\u001b[1;34m(fileobj)\u001b[0m\n\u001b[0;32m    212\u001b[0m mopt_bytes \u001b[39m=\u001b[39m fileobj\u001b[39m.\u001b[39mread(\u001b[39m4\u001b[39m)\n\u001b[0;32m    213\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mopt_bytes) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 214\u001b[0m     \u001b[39mraise\u001b[39;00m MatReadError(\u001b[39m\"\u001b[39m\u001b[39mMat file appears to be empty\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    215\u001b[0m mopt_ints \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mndarray(shape\u001b[39m=\u001b[39m(\u001b[39m4\u001b[39m,), dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39muint8, buffer\u001b[39m=\u001b[39mmopt_bytes)\n\u001b[0;32m    216\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m0\u001b[39m \u001b[39min\u001b[39;00m mopt_ints:\n",
      "\u001b[1;31mMatReadError\u001b[0m: Mat file appears to be empty"
     ]
    }
   ],
   "source": [
    "# TODO REMOCVE\n",
    "''' Mouse_Data.py\n",
    "\n",
    "    Contains the Mouse_Data class that is used for analysing the SPIKE2 data .txt files.\n",
    "    @Mik Schutte\n",
    "'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, re, datetime, scipy.io\n",
    "from scipy.io import matlab\n",
    "\n",
    "def load_mat(filename):\n",
    "    ''' This function should be called instead of direct scipy.io.loadmat\n",
    "        as it cures the problem of not properly recovering python dictionaries\n",
    "        from mat files. It calls the function check keys to cure all entries\n",
    "        which are still mat-objects\n",
    "    '''\n",
    "\n",
    "    def _check_vars(d):\n",
    "        ''' Checks if entries in dictionary are mat-objects. If yes\n",
    "            todict is called to change them to nested dictionaries\n",
    "        '''\n",
    "        for key in d:\n",
    "            if isinstance(d[key], matlab.mio5_params.mat_struct):\n",
    "                d[key] = _todict(d[key])\n",
    "            elif isinstance(d[key], np.ndarray):\n",
    "                d[key] = _toarray(d[key])\n",
    "        return d\n",
    "    \n",
    "    def _todict(matobj):\n",
    "        ''' A recursive function which constructs from matobjects nested dictionaries\n",
    "        '''\n",
    "        d = {}\n",
    "        for strg in matobj._fieldnames:\n",
    "            elem = matobj.__dict__[strg]\n",
    "            if isinstance(elem, matlab.mio5_params.mat_struct):\n",
    "                d[strg] = _todict(elem)\n",
    "            elif isinstance(elem, np.ndarray):\n",
    "                d[strg] = _toarray(elem)\n",
    "            else:\n",
    "                d[strg] = elem\n",
    "        return d\n",
    "\n",
    "    def _toarray(ndarray):\n",
    "        ''' A recursive function which constructs ndarray from cellarrays\n",
    "            (which are loaded as numpy ndarrays), recursing into the elements\n",
    "            if they contain matobjects.\n",
    "        '''\n",
    "        if ndarray.dtype != 'float64':\n",
    "            elem_list = []\n",
    "            for sub_elem in ndarray:\n",
    "                if isinstance(sub_elem, matlab.mio5_params.mat_struct):\n",
    "                    elem_list.append(_todict(sub_elem))\n",
    "                elif isinstance(sub_elem, np.ndarray):\n",
    "                    elem_list.append(_toarray(sub_elem))\n",
    "                else:\n",
    "                    elem_list.append(sub_elem)\n",
    "            return np.array(elem_list, dtype='object')\n",
    "        else:\n",
    "            return ndarray\n",
    "\n",
    "    data = scipy.io.loadmat(filename, struct_as_record=False, squeeze_me=True)\n",
    "    return _check_vars(data)\n",
    "\n",
    "def format_data(checked_data):\n",
    "    ''' Formats the checked data into a pandas DataFrame\n",
    "    '''\n",
    "    # Check for mat objects\n",
    "    df = pd.DataFrame(columns=['trialType', 'trialStart', 'trialEnd', 'stim_t', 'response_t', 'success', 'licks'])\n",
    "    df['trialType'] = checked_data['SessionData']['TrialTypes']\n",
    "    df['trialStart'] = checked_data['SessionData']['TrialStartTimestamp']\n",
    "    df['trialEnd'] = checked_data['SessionData']['TrialEndTimestamp']\n",
    "\n",
    "    stim_t = [trial['States']['Stimulus'][0] for trial in checked_data['SessionData']['RawEvents']['Trial']]\n",
    "    df['stim_t'] = checked_data['SessionData']['TrialStartTimestamp'] + stim_t\n",
    "\n",
    "    response_t = [np.diff(trial['States']['WaitForLick'])[0] for trial in checked_data['SessionData']['RawEvents']['Trial']]\n",
    "    df['response_t'] = response_t\n",
    "\n",
    "    success = [np.isnan(trial['States']['Reward'][0]) for trial in checked_data['SessionData']['RawEvents']['Trial']]\n",
    "    df['success'] = np.invert(success)\n",
    "\n",
    "    # Licks\n",
    "    for i in range(len(checked_data['SessionData']['RawEvents']['Trial'])):\n",
    "        licks = np.array([])\n",
    "        if 'Port1In' in checked_data['SessionData']['RawEvents']['Trial'][i]['Events'].keys():\n",
    "            licks = np.append(licks, checked_data['SessionData']['RawEvents']['Trial'][i]['Events']['Port1In'])\n",
    "        if 'Port1Out' in checked_data['SessionData']['RawEvents']['Trial'][i]['Events'].keys():\n",
    "            licks = np.append(licks, checked_data['SessionData']['RawEvents']['Trial'][i]['Events']['Port1Out'])\n",
    "        df['licks'].iloc[i] = sorted(licks) # Apperently this is setting with a copy, but I failed to remove this error. The outcome is correct\n",
    "    return df\n",
    "\n",
    "def concat_session(session_data, session):\n",
    "    ''' docstring\n",
    "    '''\n",
    "    # So we can already detect duplicates and they are temporally organized so if a duplicate is read it will always be succesive.\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    pass\n",
    "\n",
    "class Mouse_Data:\n",
    "    ''' Class designed for housing all data for an individual mouse\n",
    "        \n",
    "        INPUT:\n",
    "            path_to_data(str): path to the mouse folder you want to extract the data from\n",
    "            \n",
    "        OUTPUT:\n",
    "            Mouse_Data(Class): Dataclass with attributes like id, sessions, all_data and concatenated data\n",
    "    '''    \n",
    "\n",
    "    def __init__(self, path_to_data): \n",
    "        # From path_to_data get path and files in the raw-folder of that path\n",
    "        self.path = path_to_data \n",
    "        self.files = os.listdir(self.path)\n",
    "        self.id = self.files[0].split('/')[-1].split('_')[0]\n",
    "        self.get_behaviour()\n",
    "        self.sessions = [str(key) for key in self.session_data.keys()]\n",
    "        self.compile_data()\n",
    "\n",
    "    def get_behaviour(self):\n",
    "        ''' Creates self.session_data a dictionary with keys being session_dates and values being a pd.Dataframe \n",
    "        '''\n",
    "        self.session_data = {}\n",
    "        for file in self.files:\n",
    "            print(file)\n",
    "            if 'meta' not in file:\n",
    "                rawData = load_mat(self.path + file)\n",
    "                session = rawData['__header__'].decode()\n",
    "                session = re.split('Mon |Tue |Wed |Thu |Fri |Sat |Sun ', session)[-1] \n",
    "                session = str(datetime.datetime.strptime(session, '%b %d %X %Y')).split()[0] # It's possible to recover time by not slicing this string or [-1]\n",
    "                \n",
    "                # Check if a similar session is already in the dictionary\n",
    "                if session in self.session_data.keys():\n",
    "                    print(session)\n",
    "                    print(f'WARNING: There is already data loaded for the session on {session}.\\nPlease check validity.')\n",
    "                    \n",
    "                    # TODO Now lets get a concatenating function in here\n",
    "                    # sesh0 = self.session_data[session]\n",
    "                    # sesh1 = format_data(rawData)\n",
    "\n",
    "                    # # Things to concat 'trialStart', 'trialEnd', 'stim_t', 'response_t'\n",
    "                    # lastrow = sesh0.iloc[-1] \n",
    "                    # sesh1['trialStart'] += lastrow['trialStart']#\n",
    "\n",
    "                self.session_data[session] = format_data(rawData)\n",
    "    \n",
    "    def compile_data(self):\n",
    "        ''' Creates one big pd.DataFrame of all stimuli over all sessions'''\n",
    "        df_full = pd.DataFrame()\n",
    "        for session in self.sessions:\n",
    "            df_full = pd.concat([df_full, self.session_data[session]])\n",
    "        self.full_data = df_full   \n",
    "\n",
    "# Load the datafiles into Python using Mouse_Data\n",
    "# We need an aditional path string to get to the BPOD data\n",
    "BPOD_path = '/microstim/Session Data/'\n",
    "mouse_list = []\n",
    "for ID in datafiles:\n",
    "    path_to_data = root+ID+BPOD_path\n",
    "    mouse = Mouse_Data(path_to_data)\n",
    "    mouse_list.append(mouse)\n",
    "print(mouse_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trialStart</th>\n",
       "      <th>response_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trialStart  response_t\n",
       "0       0.001         0.4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trialStart</th>\n",
       "      <th>response_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trialStart  response_t\n",
       "0       0.003         1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trialStart</th>\n",
       "      <th>response_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trialStart  response_t\n",
       "0       0.001        0.45\n",
       "1       0.002        0.60\n",
       "0       0.003        1.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df0 = pd.DataFrame({'trialStart': [0.001, 0.002], 'response_t': [0.45, 0.6]})\n",
    "df1 = pd.DataFrame({'trialStart': [0.001], 'response_t': [0.4]})\n",
    "display(df1)\n",
    "df1['trialStart'] += df0.iloc[-1]['trialStart']\n",
    "df1['response_t'] += df0.iloc[-1]['response_t'] # todo not change this\n",
    "\n",
    "display(df1)\n",
    "\n",
    "df2 = pd.concat([df0, df1])\n",
    "display(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "microstim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
